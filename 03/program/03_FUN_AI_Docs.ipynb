{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP\n",
    "\n",
    "\n",
    "## 用語解説\n",
    "\n",
    "- MLPとは\n",
    "\n",
    "    Multi Layer Perceptron の略で、日本語にすると多層パーセプトロン。\n",
    "\n",
    "- パーセプトロン\n",
    "\n",
    "- 人工ニューロン\n",
    "\n",
    "- 活性化関数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "資料の流れ\n",
    "\n",
    "前回までで環境構築と深層学習のざっくりとした説明をした\n",
    "\n",
    "今回からは、実際に深層学習に触れていこうと思う\n",
    "\n",
    "まず今回は、基礎となる浅いニューラルネットワークについてみていく。\n",
    "- パーセプトロンとは\n",
    "- 重みとバイアス\n",
    "- ニューラルネットワーク\n",
    "- 活性化関数\n",
    "- 誤差関数\n",
    "- 最適化関数\n",
    "    - 最急降下法\n",
    "    - 確率的勾配法(SGD)\n",
    "- 誤差逆伝播"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### パーセプトロン\n",
    "パーセプトロンとは1957年に考案されたアルゴリズムで、現在のディープラーニングの基礎になっている重要なものである。\n",
    "\n",
    "パーセプトロンは複数の信号を受け取り、1つの信号を出力をする。ここでの信号とは、データや電流などの流れをもつものだとイメージすると良い。\n",
    "\n",
    "簡単のため、入力が2つの場合のパーセプトロンを考える。パーセプトロンの入力をそれぞれ$x_1$,$x_2$とし、それらの流れやすさ。つまり、重みを$w_1$,$w_2$。出力を$y$とする\n",
    "\n",
    "$$\n",
    "y = \\left\\{\n",
    "    \\begin{array}{cc}\n",
    "    0  &(w_1x_1 + w_2x_2 \\le 0)\\\\\n",
    "    1  &(w_1x_1 + w_2x_2 > 0)\n",
    "    \\end{array}\n",
    "    \\right.\n",
    "$$\n",
    "\n",
    "$y$の出力は0か1の2通りである。\n",
    "\n",
    "![](./fig/03/01.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptlon(x_1, x_2):\n",
    "    w_1, w_2 = 1, 1 # 重みを変えると同じ入力でもyの値が変わる\n",
    "    result = w_1*x_1 + w_2*x_2\n",
    "    y = 0\n",
    "    if result > 0:\n",
    "        y = 1\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(perceptlon(1,-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP\n",
    "全結合層のみで構成されているやつ。\n",
    "\n",
    "![](./fig/03/02.png)\n",
    "\n",
    "今回は、MLPを用いて、クラス分類をしていく。データセットはskleran が用意している 手書き文字を用いる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.moel_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "digits = load_digits()\n",
    "\n",
    "image = digits.data\n",
    "label = digits.target\n",
    "\n",
    "# NumpyのndarrayをTensorに変換\n",
    "image = torch.tensor(image, dtype=torch.float32)\n",
    "label = torch.tensor(label, dtype=torch.int64)\n",
    "\n",
    "# データセットを作成\n",
    "dataset = TensorDataset(image, label)\n",
    "# train に使う方は順番をランダムにしておく\n",
    "# ミニバッチといって、データの塊を用意しておく\n",
    "train_loader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# ネットワーク定義\n",
    "# 今回は、線形層が３層。活性化関数はReLUを用いる\n",
    "net = nn.Sequential(\n",
    "    nn.Linear(64, 32),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(32, 16),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(16, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_net(net, data_loader, device='cpu'):\n",
    "    net.eval()\n",
    "    labels = []\n",
    "    label_preds = []\n",
    "    for image, label in loader:\n",
    "        image = image.to(device)\n",
    "        label = label.to(device)\n",
    "        with torch.no_grad():\n",
    "            _, label_pred = net(image).max(1)\n",
    "        labels.append(label)\n",
    "        label_preds.append(label_pred)\n",
    "    # ミニバッチを1つに集める\n",
    "    labels = torch.cat(labels)\n",
    "    label_preds = torch.cat(label_preds)\n",
    "    # 予想精度を計算\n",
    "    acc = (labels == label_preds).float().sum() / len(labels)\n",
    "    print(acc.item())\n",
    "    return acc.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_net(net, train_loader, test_loader, optimizer=optim.Adam,\n",
    "                loss_fn = nn.CrossEntropyLoss(), n_iter=10, device='cpu'):\n",
    "    train_losses = []\n",
    "    train_acc = []\n",
    "    eval_acc = []\n",
    "    optimizer =  optimizer(net.parameters())\n",
    "    for epoch in range(n_iter):\n",
    "        running_loss = 0.\n",
    "        net.train()\n",
    "        n = 0\n",
    "        n_acc = 0\n",
    "        # プログレスバーを出す\n",
    "        for i, (image, label) in tqdm(enumerate(train_loader), total=len(train_loader)):\n",
    "            image = image.to(device)\n",
    "            label = label.to(device)\n",
    "\n",
    "            pred_label = net(image)\n",
    "            \n",
    "            loss = loss_fn(pred_label, label)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            n += len(image)\n",
    "            # 確率が一番高いやつを計算\n",
    "            _, label_pred = pred_label.max(1)\n",
    "            n_acc += (label == label_pred).float().sum().item()\n",
    "        train_losses.append(running_loss / i)\n",
    "        # 訓練データの予測精度\n",
    "        train_acc.append(n_acc / n)\n",
    "        eval_acc.append(eval_net(net, test_loader, device))\n",
    "        print(epoch, train_losses[-1], train_acc[-1], eval_acc[-1], flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "net.to(device)\n",
    "train_net(net, train_loader, test_loader, n_iter=20, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.5 64-bit ('pytorch': conda)",
   "language": "python",
   "name": "python37564bitpytorchcondac1588a0183c145a7ad887ad140edf980"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}